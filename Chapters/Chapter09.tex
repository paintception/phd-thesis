%Chapter 7

\chapter{Concluding Remarks} % Chapter title
\label{ch:upside_down_rl} % For referencing the chapter elsewhere, use \autoref{ch:introduction} 

\begin{remark}{Outline}
This is the concluding chapter of this dissertation which is divided in two parts: we start by answering the research questions that were presented at the beginning of this work. Each question is answered with respect to the research that has been presented throughout the earlier chapters of this work and is followed by a brief critical conclusion. We then move to the second part of this chapter, presented in Sec. \ref{sec:critical_discussion}, where we will critically analyze how over the last decade, the fields of supervised learning and reinforcement learning have been affected by the rise of deep neural networks and give our personal interpretation of what the future of both research fields could look like in the coming years. 
\end{remark}


\section{Answers to the Original Research Questions}
\label{sec:answers}

We now answer the research questions that we have introduced at the beginning of this manuscript and that have served as inspiration for all the work that has been presented throughout the thesis.

\begin{enumerate}
	\item \textit{Can convolutional neural networks be transferred and trained across different source and target domains? if so, which target domains could be of interest for investigating their transfer learning properties?}
	
	The research presented in Chapters \ref{ch:tl_natural_to_non_natural}, \ref{ch:minerva} and \ref{ch:tl_lth} shows that when it comes to supervised learning problems, convolutional neural networks exhibit strong transfer learning properties. In Chapter \ref{ch:tl_natural_to_non_natural} we have in fact seen that five popular neural architectures, originally designed for tackling computer vision problems on datasets containing natural images, can be transferred for targetting classification problems that come from the field of digital heritage. Furthermore, we have also empirically shown that all such pre-trained architectures, are able to learn features on datasets of natural images that generalize to the non natural image domain. Similar conclusions can also be drawn from the results presented in Chapter \ref{ch:minerva}, where we have shown that the good transfer learning properties of convolutional neural networks go beyond the computer vision task of classification, and also hold for object detection problems. Similarly to the research presented in Chapter \ref{ch:tl_natural_to_non_natural} we have again considered the field of digital heritage as target domain, as it offers numerous potentially interesting practical applications such as the one modeled by the MINERVA dataset. In Chapter \ref{ch:tl_lth} we have then seen that an equally important target domain for exploiting the transfer learning properties of pre-trained image classifiers is that of digital pathoology, as it is a field that is potentially characterized by a lack of appropriate training data, a hurdle that can strongly limit the training process of a convolutional neural network.

	While all the research presented in the second part of this thesis provides strong evidence in favour of transferring, and potentially fine-tuning, pre-trained convolutional neural networks, the same can however not be said for the results obtained in Chapter \ref{ch:dqn_transfer}, where we have instead seen that the transfer learning potential of such models can be much more limiting when it comes to the model-free deep reinforcement learning domain. 

	
	\item \textit{What Transfer Learning training strategy should be adopted to maximize the performance of pre-trained networks?}

	As presented in Chapter \ref{ch:transfer_learning}, there are two main approaches for performing transfer learning in the context of convolutional neural networks: an off-the-shelf feature extraction approach, and a fully fine-tuning approach. The research presented in Chapter \ref{ch:tl_natural_to_non_natural} clearly shows that when it comes to image classification problems, the latter training strategy results in significantly better final performance, as it allows networks to better adapt to the target domain, and therefore learn new feature representations that are relevant for the target task. The results of this study served as inspiration for the research presented in Chapter \ref{ch:minerva} where a fine-tuning training strategy was preferred over an off-the-shelf approach when tackling object detection problems and, in the end, resulted in models that were able to successfully detect musical instruments in paintings. Surprisingly, however, in Chapter \ref{ch:dqn_transfer} we have then seen that a fine-tuning transfer learning approach can be detrimental in the context of model-free deep reinforcement learning, as deep reinforcement learning agents transfer very poorly across tasks and even to themselfes. In the case of the latter, however, this only happens if a fine-tuning training strategy is adopted, and not if the networks are used as simple feature extractors.   

Despite the negative performance presented in Chapter \ref{ch:dqn_transfer} we overall still believe that if enough computational resources are available, pre-trained convolutional neural networks should always be fine-tuned, especially when it comes to supervised learning problems.

	\item \textit{Can Transfer Learning be a valuable tool for better understanding convolutional neural networks?}
	
	Throughout this thesis we have argued that convolutional neural networks should be studied from a transfer learning perspective, not only because this would allow practictioners to know whether such algorithms could be deployed outside the realm of natural images, but also because their transfer learning properties could deliver novel insights into their inner properties. The research presented in Chapters \ref{ch:tl_lth} and \ref{ch:dqn_transfer} is a clear example that shows that a better understanding of convolutional neural networks can be obtained thanks to transfer learning. In Chapter \ref{ch:tl_lth} we have used transfer learning as a tool for better understanding the phenomenon of the Lottery Ticket Hypothesis (LTH). This allowed us to show that pruned convolutional neural networks winners of the LTH contain inductive biases that are generic at least to some extent, and therefore gain a deeper understanding of this deep learning phenomenon. In Chapter \ref{ch:dqn_transfer} we have instead discovered that convolutional neural networks transfer very poorly when they get trained for solving reinforcement learning tasks in a model-free deep reinforcement learning setting. With the intent of understanding why their transfer learning potential was not on par with the one that was extensively observed in Chapters \ref{ch:tl_natural_to_non_natural} and \ref{ch:minerva}, we have gained novel insights that allowed us to show that models commonly denoted as Deep-Q Networks go through two very distinct training phases. 

We therefore believe that transfer learning is an extremely valuable tool for better understanding neural networks, as it allows to study their training process from a perspective which is unique and that goes beyond that of models that get trained from scratch.  

	
	\item \textit{Do different machine learning paradigms result in convolutional neural networks with different transfer learning properties?}

	Based on the significant gap in terms of performance between the results obtained in the second part of this dissertation, and the results obtained in the third part of this thesis, we strongly believe that the answer to this research question is \textit{yes}. Specifically, we have seen that as long as convolutional neural networks are trained for solving supervised learning tasks, then they will very likely exhibit strong transfer learning properties (see Chapters \ref{ch:tl_natural_to_non_natural} and \ref{ch:minerva}). However, if such models will be used for tackling deep reinforcement learning problems in a model-free reinforcemnt learning context, then their transfer learning potential will be much more limited. The reason of this is that when it comes to supervised learnig, convolutional neural networks will only have to serve as feature extractors, whereas the same cannot be said for model-free deep reinforcement learning, where such models have also to serve as optimal value function approximators. 

The transfer learning potential of convolutional networks is therefore highly dependant from the machine learning problem at hand, although we also believe that the poor transfer learning properties observed in Chapter \ref{ch:dqn_transfer} are inherent to model-free deep reinforcement learning algorithms only.


\end{enumerate}


\section{Critical Discussion \& Future Perspectives}
\label{sec:critical_discussion}

We now present a critical discussion which addresses some of the limitations that currently characterize the fields of deep supervised and deep reinforcement learning and see how they relate to possible future work.

\subsection{Deep Supervised Learning}
\label{sec:supervised_learning}

\paragraph{\textbf{\uppercase{D}ata and \uppercase{C}omputing \uppercase{P}ower}}
Neural networks only require two simple ingredients for tackling most of supervised learning problems: 1) large amounts of training data and 2) enough computational resources. If both of such ingredients are available, we believe that most supervised learning problems within Computer Vision can be addressed successfully. While it is true that both ingredients can not always be available to machine learning practitioners, it is also true that as extensively demonstrated throughout the second part of this thesis, one could overcome their scarcity thanks to deep transfer learning. We therefore disagree with \citet{marcus2018deep} who at the present moment considers the deep learning field as too data hungry, and believe that this is an issue that thanks to the availability of large pre-trained models has been successfully addressed.  

\paragraph{\textbf{\uppercase{C}onvolutional \uppercase{N}eural \uppercase{N}etworks and \uppercase{V}ision \uppercase{T}ransformers}}
As extensively documented throughout this dissertation, when it comes to classification and regression problems that are characterized by high-dimensional and spatially organized inputs, convolutional neural networks have become the de facto neural architecture. Yet, the last years have seen the emergence of a novel type of neural architecture called Vision Transformers (ViTs) \cite{dosovitskiy2020image}. Next to obtaining overall excellent performance in the domain of Computer Vision, ViTs also appear to be requiering substantially fewer computational resources for training. It is, therefore, natural to wonder whether this family of models could in the future become as popular as convolutional neural networks are nowadays, and even if they could eventually replace convolutional architectures completely. We certainly think that ViTs will in the coming years gain in popularity, but also that their potential within Computer Vision will highly depend from the transfer learning properties that these models will show (a research direction that at the present moment has not been thoroughly explored yet). We therefore believe that a replication of the studies presented in Chapters \ref{ch:tl_natural_to_non_natural}, \ref{ch:minerva} and \ref{ch:dqn_transfer} could certainly be of great interest to the Computer Vision and Reinforcement Learning communities, and recommend them as potential avenues for future work as recently explored by \citet{liu2021efficient}.

\subsection{Deep Reinforcement Learning}
\paragraph{\textbf{\uppercase{T}edious \uppercase{H}yperparameters}}

In Chapter \ref{ch:reinforcement_learning} we have seen that Deep Reinforcement Learning (DRL) has gained a lot of attention from the machine learning community over the last decade, as the number of successful applications showcasing its potential have in fact become countless, ranging from agents achieving super-human performance on popular boardgames such as chess and go, to neural networks able to autonomously navigate stratospheric balloons. To an untrained eye, or more simply to a RL practitioner with few years of experience, successfully training a DRL agent might look like a straightforward task. However, behind the largely acclaimed accomplishments praised by the DRL literature, there is an equivalently large, and mostly hidden, process of hyperparameter tuning which is essential for successfully training a neural network. Throughout this thesis, convolutional neural networks have been trained both in a supervised learning context as well as in a reinforcement learning one, and we have in first person experienced how unrobust and oversensitive such algorithms can be when targeting the latter type of problems. This susceptability, on the contrary, was never encountered when tackling supervised learning tasks. We believe that at the present moment, despite all of its remarkable achievements, DRL cannot yet be considered as a successful application of convolutional neural networks. As long as a state of the art Rainbow agent \cite{hessel2018rainbow} can only get successfully trained if its learning rate is set to the unintuitive value of $0.0000625$, and a DRL practitioner has to wait for weeks before being able to see a DQN agent play certain games of the Atari Arcade Learning Environment \cite{kaiser2019model}, we believe that DRL is far from being solved.


\paragraph{\textbf{\uppercase{T}he \uppercase{D}eadly \uppercase{T}riad}}
In Chapters \ref{ch:reinforcement_learning} and \ref{ch:dqv_family_of_algorithms} we have mentioned the Deadly Triad of Deep Reinforcement Learning, a combination of three elements, which if present within the same learning agent can result into algorithms that diverge and are unable to learn an approximation of an optimal value function. As one of the elements of the Deadly Triad is that of a function approximator, it naturally follows that the stability of deep reinforcement learning algorithms will constantly be questioned by the deep learning community which will regularly introduce novel neural architectures in the coming years. This raises the natural question \textit{Which element of the triad should eventually be given up when developing DRL algorithms?}. So far, the community seems to agree that giving up on function approximators is clearly not possible as neural networks will always play a crucial role in the development of future DRL algorithms \cite{van2018deep_triad,hernandez2019understanding,fedus2020revisiting} thanks to their properties that we discussed in Sec. \ref{sec:function_approximators} of Chapter \ref{ch:reinforcement_learning}. We agree with this point of view and therefore believe that either off-policy learning or bootstrapping should be given up: if the end goal is that of developing algorithms that do not diverge whilst training we believe that it is the off-policy learning element of the triad which should be withdrawn during the development of novel DRL techniques. While this could come at the price of restricting the number of possible policies that could be learned by an agent, we believe that this is a problem which could be controlled as long as agents will be combined with proper exploration policies. The DQV-Learning algorithm presented in Chapter \ref{ch:dqv_family_of_algorithms} is an example of a DRL algorithm that can avoid divergence through on-policy learning, while at the same time making use of a neural network trained through temporal-difference learning. 



\begin{takeaway}{Takeaway of Part III}

\end{takeaway}







