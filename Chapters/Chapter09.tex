%Chapter 7

\chapter{Future Perspectives \& Concluding Remarks} % Chapter title
\label{ch:upside_down_rl} % For referencing the chapter elsewhere, use \autoref{ch:introduction} 

\begin{remark}{Outline}

	


\end{remark}



\section{Answers to the Original Research Questions}

We now answer the research questions that we have originally introduced in Chapter \ref{ch:introduction} and that have served as inspiration for all the work presented throughout this thesis.

\begin{enumerate}
	\item \textit{"Can convolutional neural networks be transferred and trained across different source and target domains? if so which target domains could be of interest for investigating their transfer learning properties?"}
	
	The research presented in Chapters \ref{ch:}, \ref{ch:} and \ref{ch:} shows that when it comes to supervised learning problems, convolutional neural networks exhibit strong transfer learning properties. In Chapter \ref{ch:} we have in fact seen that five popular neural architectures, originally designed for tackling computer vision problems on datasets containing natural images, can be transferred for targetting classification problems that come from the field of digital heritage. Furthermore, we have also empirically shown that all such pre-trained architectures, are able to learn features on datasets of natural images that generalize to the non natural image domain. Similar conclusions can also be drawn from the results presented in Chapter \ref{ch:}, where we have shown that the good transfer learning properties of convolutional neural networks go beyond the computer vision task of classification, and also hold for object detection problems. Similarly to the research presented in Chapter \ref{ch:} we have again considered the field of digital heritage as target domain, as it offers numerous potentially interesting practical applications such as e.g., the one described by the MINERVA dataset. In Chapter \ref{ch:} we have then seen that an equally important target domain for exploiting the transfer learning properties of pre-trained image classifiers is that of digital pathoology, as it is a field characterized by a lack of appropriate training data, a hurdle that can strongly limit the training process of a convolutional neural network.

	While all the research presented in the second part of this thesis provides strong evidence in favour of transferring, and potentially fine-tuning, pre-trained convolutional neural networks, the same cannot be said for the results obtained in Chapter \ref{ch:}, where we have instead seen that the transfer learning potential of such models can be much more limiting when it comes to the reinforcement learning domain. 

	
	\item \textit{"What Transfer Learning training strategy should be adopted to maximize the performance of pre-trained networks?"}

	As presented in Chapter \ref{ch:}, there are two main approaches for performing transfer learning in the context of convolutional neural networks: an off-the-shelf feature extraction approach, and a fully fine-tuning approach. The research presented in Chapter \ref{ch:} clearly show that when it comes to image classification problems, the latter training strategy significantly results in better final performance. 

	\item \textit{"Can Transfer Learning be a valuable tool for better understanding convolutional neural networks?"}
	
	Throughout this thesis we have argued that convolutional neural networks should be studied from a transfer learning perspective, not only because this would allow practictioners to know whether such algorithms could be deployed to real world applications, but also because by understanding their transfer learning performance, novel insights about their inner properties can be discovered. The research presented in Chapters \ref{ch:} and \ref{ch:} is a clear example that shows that a better understanding of convolutional neural networks can be obtained thanks to transfer learning. In Chapter \ref{ch:} we have used transfer learning as a tool for better understanding the phenomenon of the Lottery Ticket Hypothesis (LTH). This allowed us to show that pruned convolutional neural networks winners of the LTH contain inductive biases that are generic at least to some extent, and therefore gain a deeper understanding of this deep learning phenomenon. In Chapter \ref{ch:} we have instead discovered that convolutional neural networks transfer very poorly when they get trained for solving reinforcement learning tasks in a model-free deep reinforcement learning setting. With the intent of understanding why their transfer learning potential was not on par with the one that was extensively observed in Chapters \ref{ch:} and \ref{ch:}, we have gained novel insights around their training process, which in turn allowed us to show that models commonly denoted as Deep-Q Networks go through two very distinct training phases. 

We therefore believe that transfer learning is an extremely valuable tool for better understanding neural networks, as it allows to study their training process from a perspective which is unique and that results in potential insights that could not be observed when simply observing the training performance of models that are just trained from scratch.  

	
	\item \textit{"Do different machine learning tasks result in convolutional neural networks with different transfer learning properties?"}

\end{enumerate}






\section{On the Future of Convolutional Neural Networks}


\section{On the Limitations of Deep Reinforcement Learning}

\begin{itemize}
\item Unfortunately, the intuition of even the most expert practitioner is not enough for identifying which learning parameters work best. As an example, let us consider the previously described Rainbow agent \cite{hessel2018rainbow}. The learning rate that yields successful training is set to $0.0000625$, clearly this is a value that could only be identified after performing an exhaustive grid search over a large set of potential learning rates. If on top of this, we also consider that training a DRL agent is a process that can last from taking days to even weeks \cite{kaiser2019model}, it is clear that  It is, therefore, desirable to develop algorithms that do not require extraordinary computational costs for training.
\item However, if an agent can bypass the need to rely on either one of these elements, then instability can already be prevented. Several work has addressed the `Deadly Triad" of DRL \cite{van2018deep_triad,hernandez2019understanding,fedus2020revisiting} to answer the natural question \textit{`which element can be given up when developing DRL algorithms?"} So far, the community seems to agree that giving up on function approximators is clearly not possible. As discussed in Sec. \ref{sec:function_approximators} even linear functions can already play a crucial role in developing algorithms that deal with large and complex MDPs. On the other hand, it is not yet known what to give up between off-policy learning and bootstrapping; what is known however, is that also because of the `Deadly Triad", successfully training DRL solutions can be computationally very expensive since long training times are required for training agents which constantly try not to diverge. 
\end{itemize}


\section{Towards More Transferable Agents}



\section{A note on Unsupervised Learning}
