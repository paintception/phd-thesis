\chapter*{Introduction}
\label{ch:introduction}

While when it comes to scientific research we usually end up with having more questions than the ones we started with, the work presented in this dissertation aims to answer the following research questions:

\begin{enumerate}
	\item \textit{"Can convolutional neural networks be transferred and trained across different source and target domains? \\ if so which target domains could be of interest for investigating their transfer learning properties?"}
		
	\item \textit{"What Transfer Learning training strategy should be adopted to maximize the performance of pre-trained networks?"}

	\item \textit{"Can Transfer Learning be a valuable tool for better understanding convolutional neural networks?"}
	
	\item \textit{"Do different machine learning tasks result in convolutional neural networks with different transfer learning properties?"}
\end{enumerate}

All research questions are placed within the deep transfer learning literature, a research direction that studies the generalization properties of convolutional neural networks as well as their degree of transferability across different domains and tasks. We answer these questions through the work that has been presented in several peer-reviewed publications. The main contributions underlying this thesis are:

\begin{itemize}
	\item \citet{sabatelli2018deep} \textit{"Deep transfer learning for art classification problems."} Proceedings of the European Conference on Computer Vision (ECCV) Workshops, 2018.
	\item \citet{sabatelli2018deepqv} \textit{Deep Quality Value (DQV) Learning."} Advances in Neural Information Processing Systems (NeurIPS), Deep Reinforcement Learning Workshop, 2018.
\item \citet{sabatelli2020transferability} \textit{"On the transferability of winning tickets in non-natural image datasets.} Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP), 2021.
	\item \citet{sabatelli2020deep} \textit{"The deep quality-value family of deep reinforcement learning algorithms"} Proceedings of the International Joint Conference on Neural Networks (IJCNN). IEEE, 2020.
	\item \citet{sabatelli2021advances} \textit{"Advances in Digital Music Iconography: Benchmarking the detection of musical instruments in unrestricted, non-photorealistic images from the artistic domain."} DHQ: Digital Humanities Quarterly 15.1 2021.
	\item \textit{"On the Transferability of Deep-Q Networks."} Under Review. 
\end{itemize}

Throughout the Ph.D. several other peer-reviewed papers have been published, however these are not directly presented in this thesis. The following works are either the result of external collaborations, or have served for reporting preliminary results of ongoing research:

\begin{itemize}
	\item \citet{sabatelli2019approximating}  \textit{"Approximating two value functions instead of one: towards characterizing a new family of Deep Reinforcement Learning algorithms"} Advances in Neural Information Processing Systems (NeurIPS), Deep Reinforcement Learning Workshop, 2019
	\item \citet{leroy21qvmix} \textit{"QVMix and QVMix-Max: Extending the Deep Quality-Value Family of Algorithms to Cooperative Multi-Agent Reinforcement Learning."} Proceedings of the AAAI-21 Workshop on Reinforcement Learning in Games, 2021. 
	\item \citet{hammond2020forest} \textit{"Forest Fire Control with Learning from Demonstration and Reinforcement Learning".} Proceedings of the International Joint Conference on Neural Networks (IJCNN). IEEE, 2020.
	\item \citet{banartransfer} \textit{"Transfer Learning with Style Transfer between the Photorealistic and Artistic Domain."} IS&T International Symposium on Electronic Imaging. Computer Vision and Image Analysis of Art, 2021.
	\item \citet{sasso2021fractional} \textit{"Fractional Transfer Learning for Deep Model-Based Reinforcement Learning."} \\ ArXiv preprint arXiv:2108.06526. 

\end{itemize}
